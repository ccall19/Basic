{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bc09e1",
   "metadata": {},
   "source": [
    "# 0 创建 数据库 客户端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb1ff50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lllsh/.local/lib/python3.10/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient, DataType, Function, FunctionType\n",
    "\n",
    "milvus_client = MilvusClient(uri=\"./milvus_demo.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d34872",
   "metadata": {},
   "source": [
    "# 1 加载文档 md\n",
    "\n",
    "URI = './doc/md/LangChain V1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a3a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './doc/md/LangChain V1.0/'\n",
    "\n",
    "import glob\n",
    "from langchain_text_splitters  import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "text_line = []\n",
    "\n",
    "for file_path in glob.glob(path + \"*.md\"):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    md_header_splits = markdown_splitter.split_text(text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,  # 每个块最大字符数\n",
    "        chunk_overlap=200,  # 重叠字符数\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 分割优先级\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(md_header_splits)\n",
    "\n",
    "    text_line = [chunk.page_content for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b0a217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Next, build a practical weather forecasting agent that demonstrates key production concepts:  \n",
      "1. **Detailed system prompts** for better agent behavior\n",
      "2. **Create tools** that integrate with external data\n",
      "3. **Model configuration** for consistent responses\n",
      "4. **Structured output** for predictable results\n",
      "5. **Conversational memory** for chat-like interactions\n",
      "6. **Create and run the agent** create a fully functional agent  \n",
      "Let's walk through each step:  \n",
      "<Steps>\n",
      "<Step title=\"Define the system prompt\">\n",
      "The system prompt defines your agent’s role and behavior. Keep it specific and actionable:  \n",
      "```python wrap theme={null}\n",
      "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
      "\n",
      "You have access to two tools:\n"
     ]
    }
   ],
   "source": [
    "# len(glob.glob(path + \"*.md\"))\n",
    "print(len(text_line),text_line[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054764fe",
   "metadata": {},
   "source": [
    "# 2 准备嵌入模型 GLM ： embedding3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02266739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU zhipuai\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"ZHIPUAI_API_KEY\"):\n",
    "    os.environ[\"ZHIPUAI_API_KEY\"] = getpass.getpass(\"Enter your ZhipuAI API key: \")\n",
    "\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "\n",
    "dim = 512\n",
    "embeddings = ZhipuAIEmbeddings(\n",
    "    model=\"embedding-3\",\n",
    "    # With the `embedding-3` class\n",
    "    # of models, you can specify the size\n",
    "    # of the embeddings you want returned.\n",
    "    dimensions=dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299b617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    ''' return  embedding vector for a given text '''\n",
    "    response = []\n",
    "    for line in text:\n",
    "        embedding_vectore = embeddings.embed_query(line)\n",
    "        response.append(embedding_vectore)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d06c04",
   "metadata": {},
   "source": [
    "# 3 将数据载入 Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc361aad",
   "metadata": {},
   "source": [
    "## 3.1 创建 Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc7c06",
   "metadata": {},
   "source": [
    "### 3.1.1 设计 schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb03208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto_id': False, 'description': '', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 512}}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4000}}, {'name': 'sparse', 'description': '', 'type': <DataType.SPARSE_FLOAT_VECTOR: 104>}], 'enable_dynamic_field': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = MilvusClient.create_schema()\n",
    "\n",
    "# primery field\n",
    "schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True, auto_id=True)\n",
    "# vector field\n",
    "schema.add_field(field_name=\"embedding\", datatype=DataType.FLOAT_VECTOR, dim=dim)\n",
    "# text field\n",
    "schema.add_field(field_name=\"text\", datatype=DataType.VARCHAR, max_length=4000, enable_analyze=True)\n",
    "# sparse vector field\n",
    "schema.add_field(field_name=\"sparse\", datatype=DataType.SPARSE_FLOAT_VECTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdfb552",
   "metadata": {},
   "source": [
    "### 3.1.2 定义一个将文本转换为稀疏向量表示的函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4a28c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto_id': False, 'description': '', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 512}}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4000}}, {'name': 'sparse', 'description': '', 'type': <DataType.SPARSE_FLOAT_VECTOR: 104>, 'is_function_output': True}], 'enable_dynamic_field': False, 'functions': [{'name': 'text_bm25_emb', 'description': '', 'type': <FunctionType.BM25: 1>, 'input_field_names': ['text'], 'output_field_names': ['sparse'], 'params': {}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_function = Function(\n",
    "    name=\"text_bm25_emb\", # Function name\n",
    "    input_field_names=[\"text\"], # Name of the VARCHAR field containing raw text data\n",
    "    output_field_names=[\"sparse\"], # Name of the SPARSE_FLOAT_VECTOR field reserved to store generated embeddings\n",
    "    function_type=FunctionType.BM25, # Set to `BM25`\n",
    ")\n",
    "\n",
    "schema.add_function(bm25_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b8abf",
   "metadata": {},
   "source": [
    "### 3.1.3 配置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00573420",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = milvus_client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"sparse\",\n",
    "\n",
    "    index_type=\"SPARSE_INVERTED_INDEX\",\n",
    "    metric_type=\"BM25\",\n",
    "    params={\n",
    "        \"inverted_index_algo\": \"DAAT_MAXSCORE\",\n",
    "        \"bm25_k1\": 1.2,\n",
    "        \"bm25_b\": 0.75\n",
    "    }\n",
    ")\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_type=\"AUTOINDEX\",\n",
    "    metric_type=\"IP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fac7bd",
   "metadata": {},
   "source": [
    "### 3.1.4 创建 collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c5ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"rag_langchain_v1\"\n",
    "\n",
    "# if the collection already exists, drop it\n",
    "if milvus_client.has_collection(collection_name):\n",
    "    milvus_client.drop_collection(collection_name)\n",
    "\n",
    "milvus_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    schema=schema,\n",
    "    consistency_level=\"Bounded\", # 数据一致性 需要写笔记学习一下\n",
    "    index_params=index_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4980cac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes before creation: ['embedding', 'sparse']\n"
     ]
    }
   ],
   "source": [
    "indexes = milvus_client.list_indexes(collection_name)\n",
    "print(\"Indexes before creation:\", indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97f3f5",
   "metadata": {},
   "source": [
    "## 3.2 插入数据\n",
    "文档 位于 ./doc/LangChain V1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d147df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(text_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3705d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 20/20 [00:00<00:00, 37820.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'insert_count': 20, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], 'cost': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "embeddings_list = get_embedding(text_line)\n",
    "\n",
    "for i, line in enumerate(tqdm(text_line, desc=\"Creating embeddings\")):\n",
    "    data.append({\n",
    "        \"id\": i,\n",
    "        \"embedding\": embeddings_list[i],\n",
    "        \"text\": line,\n",
    "    })\n",
    "milvus_client.insert(collection_name=collection_name, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b387b5",
   "metadata": {},
   "source": [
    "# 4 构建 RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a8cd1",
   "metadata": {},
   "source": [
    "## 检索数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "777d209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \" What's the new feature of LangChain V1.0?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "260267ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1 <class 'list'> 512\n"
     ]
    }
   ],
   "source": [
    "embedding = get_embedding([question])\n",
    "print(type(embedding), len(embedding), type(embedding[0]), len(embedding[0]))  # 检查类型和前5个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57d4a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_res = milvus_client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=get_embedding([question]),  # Use the `get_embedding` function to convert the question to an embedding vector\n",
    "    limit=3,  # Return top 3 results\n",
    "    anns_field=\"embedding\",\n",
    "    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
    "    output_fields=[\"text\"],  # Return the text field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f83968c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    [\n",
      "        \"print(response['structured_response'])\\n# ResponseFormat(\\n#     punny_response=\\\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\\\",\\n#     weather_conditions=None\\n# )\\n```\\n</Expandable>  \\n<Tip>\\nTo learn how to trace your agent with LangSmith, see the [LangSmith documentation](/langsmith/trace-with-langchain).\\n</Tip>  \\nCongratulations! You now have an AI agent that can:  \\n* **Understand context** and remember conversations\\n* **Use multiple tools** intelligently\\n* **Provide structured responses** in a consistent format\\n* **Handle user-specific information** through context\",\n",
      "        0.20912817120552063\n",
      "    ],\n",
      "    [\n",
      "        \"from langchain.agents import create_agent\\nfrom langchain.chat_models import init_chat_model\\nfrom langchain.tools import tool, ToolRuntime\\nfrom langgraph.checkpoint.memory import InMemorySaver\\nfrom langchain.agents.structured_output import ToolStrategy\\n\\n\\n# Define system prompt\\nSYSTEM_PROMPT = \\\"\\\"\\\"You are an expert weather forecaster, who speaks in puns.\\n\\nYou have access to two tools:\\n\\n- get_weather_for_location: use this to get the weather for a specific location\\n- get_user_location: use this to get the user's location\\n\\nIf a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\\\"\\\"\\\"\",\n",
      "        0.2008851170539856\n",
      "    ],\n",
      "    [\n",
      "        \"checkpointer = InMemorySaver()\\n```  \\n<Info>\\nIn production, use a persistent checkpointer that saves to a database.\\nSee [Add and manage memory](/oss/python/langgraph/add-memory#manage-short-term-memory) for more details.\\n</Info>\\n</Step>  \\n<Step title=\\\"Create and run the agent\\\">\\nNow assemble your agent with all the components and run it!  \\n```python  theme={null}\\nfrom langchain.agents.structured_output import ToolStrategy\\n\\nagent = create_agent(\\nmodel=model,\\nsystem_prompt=SYSTEM_PROMPT,\\ntools=[get_user_location, get_weather_for_location],\\ncontext_schema=Context,\\nresponse_format=ToolStrategy(ResponseFormat),\\ncheckpointer=checkpointer\\n)\\n\\n# `thread_id` is a unique identifier for a given conversation.\\nconfig = {\\\"configurable\\\": {\\\"thread_id\\\": \\\"1\\\"}}\",\n",
      "        0.19055290520191193\n",
      "    ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "retrieved_lines_with_distances = [\n",
    "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
    "]\n",
    "print(json.dumps(retrieved_lines_with_distances, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
