{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0284e937",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "æ–‡æ¡£å¼€ç¯‡æŒ‡å‡ºï¼ŒLLMæ˜¯å¾ˆç‰›äº†ï¼Œä½†è¿˜æœ‰ä¿©å…³é”®çš„ä¸è¶³ä¹‹å¤„ï¼š\n",
    "- ä¸Šä¸‹æ–‡æœ‰é™ï¼šä¸èƒ½ä¸€æ¬¡æ‘„å–å…¨éƒ¨çš„é¢„æ–™\n",
    "- é™æ€çŸ¥è¯†ï¼šåªèƒ½ä¾èµ–è®­ç»ƒè¯­æ–™\n",
    "\n",
    "Retrieval-Augmented Generation (RAG)ï¼šenhancing an LLMâ€™s answers with context-specific information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901cd85e",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹ä¸º ç›¸å…³æ­¥éª¤ï¼š\n",
    "- Document loaders\n",
    "- â­Text splitters\n",
    "- Embedding models\n",
    "- â­Vector stores\n",
    "- â­Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9958d0",
   "metadata": {},
   "source": [
    "## 1 Document loaders\n",
    "\n",
    "All document loaders implement the [`BaseLoader`](https://reference.langchain.com/python/langchain_core/document_loaders/#langchain_core.document_loaders.BaseLoader) interface.\n",
    "\n",
    "### Interface\n",
    "æ‰€æœ‰ æ–‡æ¡£åŠ è½½å™¨ éƒ½æœ‰ä¸€ä¸ªå…±äº«çš„ API ï¼š\n",
    "- .load() â€“ Loads all documents at once.\n",
    "- .lazy_load() â€“ Streams documents lazily, useful for large datasets.\n",
    "\n",
    "æŸ¥çœ‹æ”¯æŒçš„ [`æ–‡æ¡£åŠ è½½å™¨`](https://docs.langchain.com/oss/python/integrations/document_loaders#by-category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865556ef",
   "metadata": {},
   "source": [
    "## 2 Text splitters\n",
    "å°†å¤§çš„æ–‡æ¡£åˆ†å‰²ä¸ºå°çš„ chunkï¼Œä»¥ä¾›ç‹¬ç«‹æ£€ç´¢å¹¶ é€‚é…å¤§æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ã€‚ ä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ç±»åˆ†å‰²ç­–ç•¥ï¼š\n",
    "### 2.1. æ–‡æœ¬ç»“æ„åˆ†å‰²ï¼ˆText Structure-basedï¼‰\n",
    "åŸºäºæ–‡æœ¬çš„è‡ªç„¶å±‚çº§ç»“æ„è¿›è¡Œåˆ†å‰²ã€‚ç”¨ [`RecursiveCharacterTextSplitter`](https://docs.langchain.com/oss/python/integrations/splitters/recursive_text_splitter) å®ç°ã€‚        \n",
    "å®ƒæŒ‰ç…§ é€’å½’ çš„æ–¹å¼å¤„ç†ï¼š        \n",
    "\n",
    "é¦–å…ˆå°è¯•ä¿æŒè¾ƒå¤§å•ä½å®Œæ•´ï¼ˆå¦‚æ®µè½ï¼‰å¦‚æœè¶…è¿‡å—å¤§å°ï¼Œé™çº§åˆ°å¥å­çº§åˆ«ï¼Œç»§ç»­å‘ä¸‹é™çº§åˆ°å•è¯çº§åˆ«ï¼š      \n",
    "\n",
    "````py\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,        # å—å¤§å°\n",
    "        chunk_overlap=200,      # å—ä¹‹é—´çš„é‡å ï¼ˆä¿ç•™ä¸Šä¸‹æ–‡ï¼‰\n",
    "        add_start_index=True    # ä¿ç•™åŸå§‹æ–‡æ¡£ä¸­çš„èµ·å§‹ä½ç½®\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "    # é»˜è®¤çš„åˆ†éš”ç¬¦åˆ—è¡¨é¡ºåºï¼ˆè‹±æ–‡ï¼‰\n",
    "    separators = [\n",
    "        \"\\n\\n\",      # æ®µè½åˆ†éš”ç¬¦ï¼ˆç©ºç™½è¡Œï¼‰- ä¼˜å…ˆçº§æœ€é«˜\n",
    "        \"\\n\",        # å¥å­åˆ†éš”ç¬¦ï¼ˆæ¢è¡Œç¬¦ï¼‰\n",
    "        \" \",         # å•è¯åˆ†éš”ç¬¦ï¼ˆç©ºæ ¼ï¼‰\n",
    "        \"\"           # å­—ç¬¦åˆ†éš”ç¬¦ï¼ˆæœ€åæ‰‹æ®µï¼‰\n",
    "    ]\n",
    "````\n",
    "\n",
    "### 2.2. é•¿åº¦åˆ†å‰²ï¼ˆLength-basedï¼‰\n",
    "æ ¹æ®é•¿åº¦é™åˆ¶ï¼ˆå­—ç¬¦æ•°æˆ– token æ•°ï¼‰è¿›è¡Œåˆ†å‰²ã€‚         \n",
    "- å­—ç¬¦åˆ†å‰²\n",
    "````py\n",
    "    from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "    chunks = text_splitter.split_text(document)\n",
    "````\n",
    "- Token åˆ†å‰²\n",
    "````py\n",
    "    from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        encoding_name=\"cl100k_base\",  # OpenAI ç¼–ç \n",
    "        chunk_size=100,               # Token æ•°é‡\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "    chunks = text_splitter.split_text(document)\n",
    "````\n",
    "\n",
    "### 2.3. æ–‡æ¡£ç»“æ„åˆ†å‰²ï¼ˆDocument Structure-basedï¼‰\n",
    "æ ¹æ®æ–‡æ¡£æœ¬èº«çš„æ ¼å¼ï¼ˆcodeã€HTMLã€Markdownã€JSON ç­‰ï¼‰è¿›è¡Œåˆ†å‰²ã€‚è¿™ç±»æ–‡æ¡£æœ¬èº«å°±å…·æœ‰æ˜æ˜¾çš„ç»“æ„ã€‚       \n",
    "è¯¦ç»†ä»£ç å‚çœ‹ [`å®˜æ–¹æ–‡æ¡£ç¤ºä¾‹`](https://docs.langchain.com/oss/python/integrations/splitters#document-structure-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f179a",
   "metadata": {},
   "source": [
    "## 3 Embedding Model\n",
    "å„å®¶Embedding æ¨¡å‹ é›†æˆå‚è€ƒï¼š[`Top integrations`](https://docs.langchain.com/oss/python/integrations/text_embedding#top-integrations) [`All embedding models`](https://docs.langchain.com/oss/python/integrations/text_embedding#all-embedding-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc02401",
   "metadata": {},
   "source": [
    "## 4 Vector stores\n",
    "\n",
    "å·²é›†æˆçš„ å‘é‡æ•°æ®åº“ï¼š[`All vector stores`](https://docs.langchain.com/oss/python/integrations/vectorstores#all-vector-stores)\n",
    "\n",
    "A vector store `stores embedded data` and performs `similarity search`.     \n",
    "\n",
    "```mermaid  theme={null}\n",
    "flowchart LR\n",
    "\n",
    "    subgraph \"ğŸ“¥ Indexing phase (store)\"\n",
    "        A[ğŸ“„ Documents] --> B[ğŸ”¢ Embedding model]\n",
    "        B --> C[ğŸ”˜ Embedding vectors]\n",
    "        C --> D[(Vector store)]\n",
    "    end\n",
    "\n",
    "    subgraph \"ğŸ“¤ Query phase (retrieval)\"\n",
    "        E[â“ Query text] --> F[ğŸ”¢ Embedding model]\n",
    "        F --> G[ğŸ”˜ Query vector]\n",
    "        G --> H[ğŸ” Similarity search]\n",
    "        H --> D\n",
    "        D --> I[ğŸ“„ Top-k results]\n",
    "    end\n",
    "```\n",
    "\n",
    "### Interface\n",
    "LC æä¾›äº†ä¸€äº›ç»Ÿä¸€çš„æ¥å£ç”¨äºï¼š\n",
    "- add_documents - Add documents to the store.\n",
    "- delete - Remove stored documents by ID.\n",
    "- similarity_search - Query for semantically similar documents.\n",
    "\n",
    "### Initialization\n",
    "éœ€è¦æä¾›ä¸€ä¸ª embedding æ¨¡å‹ï¼š\n",
    "````py\n",
    "    from langchain_core.vectorstores import InMemoryVectorStore\n",
    "    vector_store = InMemoryVectorStore(embedding=SomeEmbeddingModel())\n",
    "````\n",
    "\n",
    "### æ·»åŠ ã€åˆ é™¤æ–‡æ¡£ã€ç›¸ä¼¼æ€§æœç´¢\n",
    "\n",
    "````py\n",
    "    # æ·»åŠ ï¼šæ–‡æ¡£å¯¹è±¡åŠ id\n",
    "    vector_store.add_documents(documents=[doc1, doc2], ids=[\"id1\", \"id2\"])\n",
    "    # åˆ é™¤ï¼šid\n",
    "    vector_store.delete(ids=[\"id1\"])\n",
    "    # ç›¸ä¼¼æ€§æœç´¢ï¼šquery\n",
    "    similar_docs = vector_store.similarity_search(\"your query here\", k, filter={\"source\": \"tweets\"})\n",
    "````\n",
    "\n",
    "### Similarity metrics & indexing\n",
    "ç›¸ä¼¼åº¦è®¡ç®—çš„ ä¸‰ç±»å¸¸è§æ–¹æ³•ï¼š\n",
    "- Cosine similarity\n",
    "- Euclidean distance\n",
    "- Dot product       \n",
    "\n",
    "æˆ–è€… Vector stores è‡ªèº«æä¾›çš„ä¸€äº›æ–¹æ³•ã€‚\n",
    "\n",
    "### Metadata filtering\n",
    "æŒ‰å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æ¥æºã€æ—¥æœŸï¼‰ç­›é€‰å¯ä»¥ä¼˜åŒ–æœç´¢ç»“æœï¼š\n",
    "````py\n",
    "    vector_store.similarity_search(\n",
    "    \"query\",\n",
    "    k=3,\n",
    "    filter={\"source\": \"tweets\"}\n",
    "    )\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e96723",
   "metadata": {},
   "source": [
    "## 5 Retrievers\n",
    "æ£€ç´¢å™¨æ˜¯ä¸€ä¸ªæ¥å£ï¼Œå®ƒæ ¹æ®éç»“æ„åŒ–æŸ¥è¯¢è¿”å›æ–‡æ¡£ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„ retrievers ï¼Œå…¨éƒ¨çš„ retrievers å‚è€ƒ [`All retrievers`](https://docs.langchain.com/oss/python/integrations/retrievers#all-retrievers)ï¼š\n",
    "| Retriever                                                                                | Self-host | Cloud offering | Package                                                                                                                                                                               |\n",
    "| ---------------------------------------------------------------------------------------- | --------- | -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| [`AmazonKnowledgeBasesRetriever`](/oss/python/integrations/retrievers/bedrock)           | âŒ         | âœ…              | [`langchain-aws`](https://python.langchain.com/api_reference/aws/retrievers/langchain_aws.retrievers.bedrock.AmazonKnowledgeBasesRetriever.html)                                      |\n",
    "| [`AzureAISearchRetriever`](/oss/python/integrations/retrievers/azure_ai_search)          | âŒ         | âœ…              | [`langchain-community`](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever.html)                   |\n",
    "| [`ElasticsearchRetriever`](/oss/python/integrations/retrievers/elasticsearch_retriever)  | âœ…         | âœ…              | [`langchain-elasticsearch`](https://python.langchain.com/api_reference/elasticsearch/retrievers/langchain_elasticsearch.retrievers.ElasticsearchRetriever.html)                       |\n",
    "| [`VertexAISearchRetriever`](/oss/python/integrations/retrievers/google_vertex_ai_search) | âŒ         | âœ…              | [`langchain-google-community`](https://python.langchain.com/api_reference/google_community/vertex_ai_search/langchain_google_community.vertex_ai_search.VertexAISearchRetriever.html) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988823b2",
   "metadata": {},
   "source": [
    "### 5.1 milvus\n",
    "ä»¥ milvus ä¸ºä¾‹ã€‚\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
