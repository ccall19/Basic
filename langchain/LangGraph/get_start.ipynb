{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e502dc1",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "有两种 API 可供选择：\n",
    "- [Use the Graph API](https://docs.langchain.com/oss/python/langgraph/quickstart#use-the-graph-api) if you prefer to define your agent **as a graph of nodes and edges.**\n",
    "- [Use the Functional API](https://docs.langchain.com/oss/python/langgraph/quickstart#use-the-functional-api) if you prefer to define your agent **as a single function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f72c98",
   "metadata": {},
   "source": [
    "接下来用 Graph API 给出一个完整的流程：\n",
    "\n",
    "1. Define tools and model\n",
    "2. Define state\n",
    "3. Define model node\n",
    "4. Define tool node\n",
    "5. Define end logic\n",
    "6. Build and compile the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6a627",
   "metadata": {},
   "source": [
    "## 1. Define tools and model\n",
    "这部分主要是 用 LangChain 的 API 来实现。不再赘述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0a506",
   "metadata": {},
   "source": [
    "## 2. Define state\n",
    "图的 State 是用来 存储 messages 和 the number of LLM calls. 同样参看 LangChain。\n",
    "\n",
    "````py\n",
    "    from langchain.messages import AnyMessage\n",
    "    from typing_extensions import TypedDict, Annotated\n",
    "    import operator\n",
    "\n",
    "\n",
    "    class MessagesState(TypedDict):\n",
    "        messages: Annotated[list[AnyMessage], operator.add]\n",
    "        llm_calls: int\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376a1fc",
   "metadata": {},
   "source": [
    "## 3. Define model node\n",
    "提供模型调用的函数\n",
    "````py\n",
    "from langchain.messages import SystemMessage\n",
    "\n",
    "\n",
    "def llm_call(state: dict):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            model_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ],\n",
    "        \"llm_calls\": state.get('llm_calls', 0) + 1\n",
    "    }\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fcf90",
   "metadata": {},
   "source": [
    "## 4. Define tool node\n",
    "The tool node is used to call the tools and return the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3488243",
   "metadata": {},
   "source": [
    "## 5. Define end logic\n",
    "定义终止，根据模型是否发起 工具调用 来路由到对应节点 或是 END 节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4a293",
   "metadata": {},
   "source": [
    "## 6. Build and compile the agent\n",
    "The agent is built using the StateGraph class and compiled using the compile method.代码示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    [\"tool_node\", END]\n",
    ")\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show the agent\n",
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "from langchain.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
