{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa47e48",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -U langchain\n",
    "# Requires Python 3.10+\n",
    "# Installing the OpenAI integration\n",
    "pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314569c8",
   "metadata": {},
   "source": [
    "# 构建 Agent 的一些核心要素\n",
    "1. 系统提示词：Detailed system prompts for better agent behavior\n",
    "2. 工具函数：Create tools that integrate with external data\n",
    "3. 模型配置：Model configuration for consistent response1s\n",
    "4. 标准化输出：Structured output for predictable results\n",
    "5. 会话记忆： Conversational memory for chat-like interactions\n",
    "6. 创建并运行：Create and run the agent create a fully functional agent\n",
    "\n",
    "# 接下来：        \n",
    "- Build a basic agent：一个简单的例子\n",
    "- Build a real-world agent：更接近真实的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8c686",
   "metadata": {},
   "source": [
    "# 1 Build a basic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25f0678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个超级简单的Agent\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"5a4a5c93bdc34d8caac98deac76ecc82.uQpxDjyCez9svVjW\"\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "def des_animal(animal: str) -> str:\n",
    "    \"\"\"Describe an animal.\"\"\"\n",
    "    return f\"{animal} are very cute animals.\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"glm-4.6\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    )\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, des_animal],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "response1 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "response2 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"describe panda\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c09ce",
   "metadata": {},
   "source": [
    "## 查看 返回值 的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de6543c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> <class 'list'> dict_keys(['messages']) 4 \n",
      " <class 'langchain_core.messages.human.HumanMessage'> \n",
      " <class 'langchain_core.messages.ai.AIMessage'> \n",
      " <class 'langchain_core.messages.tool.ToolMessage'> \n",
      " <class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response1),type(response1['messages']), response1.keys(),len(response1['messages']),'\\n', \n",
    "      type(response1['messages'][0]), '\\n',\n",
    "      type(response1['messages'][1]), '\\n',\n",
    "      type(response1['messages'][2]), '\\n',\n",
    "      type(response1['messages'][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35b2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the weather in sf \n",
      "---\n",
      " \n",
      "I'll check the weather in San Francisco for you.\n",
      " \n",
      "---\n",
      " It's always sunny in San Francisco! \n",
      "---\n",
      " \n",
      "The weather function indicates that \"It's always sunny in San Francisco!\" \n",
      "\n",
      "However, this seems to be a generic response rather than actual current weather data. For real-time weather information in San Francisco, you might want to check a reliable weather service or app for the most accurate and up-to-date conditions, including temperature, humidity, wind speed, and any weather alerts.\n"
     ]
    }
   ],
   "source": [
    "print(response1['messages'][0].content, '\\n---\\n',\n",
    "        response1['messages'][1].content, '\\n---\\n',\n",
    "        response1['messages'][2].content, '\\n---\\n',\n",
    "        response1['messages'][3].content\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f2da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "describe panda \n",
      "---\n",
      " \n",
      " \n",
      "---\n",
      " panda are very cute animals. \n",
      "---\n",
      " \n",
      "Pandas are very cute animals! They are known for their distinctive black and white coloring, with black patches around their eyes, ears, and across their round bodies. These gentle giants are native to China and primarily eat bamboo - they can consume 20-40 pounds of bamboo per day! \n",
      "\n",
      "Pandas are known for their playful and sometimes clumsy behavior, and they spend most of their time eating or sleeping. They're solitary animals in the wild but are beloved around the world as symbols of wildlife conservation. Unfortunately, they are classified as vulnerable due to habitat loss, but conservation efforts have helped their populations slowly recover.\n"
     ]
    }
   ],
   "source": [
    "print(response2['messages'][0].content, '\\n---\\n',\n",
    "      response2['messages'][1].content, '\\n---\\n',\n",
    "      response2['messages'][2],response2['messages'][2].content, '\\n---\\n',\n",
    "      response2['messages'][3].content\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d54ede",
   "metadata": {},
   "source": [
    "# 2 Build a real-world agent\n",
    "依据六个核心要素 逐步实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bfaf15",
   "metadata": {},
   "source": [
    "### 1. Define the SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描述我们实现了两个 tools：get_weather_for_location 和 get_user_location\n",
    "# 以此告诉模型在用户询问天气时要确保知道位置，如果不确定位置，就调用 get_user_location 工具来获取用户的位置。\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a96a1",
   "metadata": {},
   "source": [
    "### 2. Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "# 这个 @tool 装饰器 会将普通函数 转换为 tool\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "\n",
    "    #Tools should be well-documented: their name, description, and argument names become part of the model’s prompt. \n",
    "    # LangChain’s @tool decorator adds metadata and enables runtime injection via the ToolRuntime parameter.\n",
    "\n",
    "    # 针对这个 ToolRuntime，我们定义了一个 Context 数据类 来描述上下文结构，目前看出来的作用是简化参数的传递，方便管理参数。\n",
    "\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    \n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf3aab6",
   "metadata": {},
   "source": [
    "### 3 Configure your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "加载模型与参数，GLM系列模型加载参考上文\n",
    "一般来说，有四种方式加载模型：\n",
    "1. 使用 langchain_openai 库中的 ChatOpenAI 类\n",
    "2. OpenAI API 直接调用或兼容调用\n",
    "3. Claude API 直接调用或兼容调用\n",
    "4. 模型本身 的 官方 SDK\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a42b1af",
   "metadata": {},
   "source": [
    "### 4 Define response format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfadff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选的结构化输出。Optionally, define a structured response format if you need the agent responses to match a specific schema.\n",
    "# 通过 dataclasses 装饰器来实现\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2382d2",
   "metadata": {},
   "source": [
    "### 5 Add memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 记忆模块，生产中，使用一个持久化的 checkpointer 将数据存到数据库\n",
    "# In production, use a persistent checkpointer that saves to a database.\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f166e7",
   "metadata": {},
   "source": [
    "### 6 Create and run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd67f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ResponseFormat,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "# 取名怪怪的，区分不同的对话\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665e8da",
   "metadata": {},
   "source": [
    "# 完整代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e444a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "# Define system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\"\n",
    "\n",
    "# Define context schema\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
    "\n",
    "# Configure model\n",
    "model = init_chat_model(\n",
    "    \"claude-sonnet-4-5-20250929\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Define response format\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None\n",
    "\n",
    "# Set up memory\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# Create agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ResponseFormat,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# Run agent\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
